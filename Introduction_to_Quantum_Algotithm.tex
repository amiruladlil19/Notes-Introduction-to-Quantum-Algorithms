\documentclass[11pt]{article}

\usepackage{geometry} \geometry{verbose,letterpaper,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
\usepackage{float}
\usepackage{amsmath}
\usepackage{kotex}
\usepackage{graphicx}
\usepackage{amssymb,bm}
%\usepackage{esint}
%\usepackage{graphicx,subfig}
\usepackage[mathscr]{euscript}
\newtheorem{theorem}{Theorem}

\makeatletter
\include{HShinInclude}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%\floatstyle{ruled}
%\newfloat{algorithm}{tbp}{loa} \floatname{algorithm}{Algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage{cite}
%,algorithmic}

%%\usepackage[usenames]{color}
\usepackage{setspace}
%\usepackage[labelfont=bf,textfont=it,normalsize]{caption}
\usepackage[labelfont=bf,small]{caption}

\usepackage{subfigure}
\usepackage{psfrag}
\usepackage{rotating}

\usepackage{multirow}
\usepackage{stfloats}
\usepackage{tabularx}
%\include{HShinIncludeV1_11}
\usepackage{pifont,xcolor}

\newcommand{\colouritem}[1]{%
	{\color{#1}\item\leavevmode}\ignorespaces%
}
%%%%%% Fox H-Variable %%%%%%%%%%%%%%%%%

\newcommand{\pSet}{\mathcal{P}}
\newcommand{\FoxD}[1]{\mathscr{H}\left(#1\right)}
\newcommand{\FoxV}[5]{\mathscr{H}^{#1,#2}_{#3,#4}\left(#5\right)}
\newcommand{\Fox}[5]{H^{#1,#2}_{#3,#4}\left(#5\right)}
\newcommand{\pDefine}[1]{\mathpzc{#1}}
\newcommand{\pC}{\pDefine{c}}
\newcommand{\pM}{\pDefine{m}}
\newcommand{\pN}{\pDefine{n}}
\newcommand{\pP}{\pDefine{p}}
\newcommand{\pQ}{\pDefine{q}}
\newcommand{\pK}{\pDefine{k}}
\newcommand{\pA}[1]{\pDefine{a}_{#1}}
\newcommand{\pB}[1]{\pDefine{b}_{#1}}
\newcommand{\pS}[1]{\pDefine{A}_{#1}}
\newcommand{\pT}[1]{\pDefine{B}_{#1}}
\newcommand{\aV}{\BB{\pDefine{a}}}
\newcommand{\bV}{\BB{\pDefine{b}}}
\newcommand{\sV}{\BB{\pDefine{A}}}
\newcommand{\tV}{\BB{\pDefine{B}}}
\newcommand{\aVn}{\aV^{\left(1\right)}}
\newcommand{\aVp}{\aV^{\left(2\right)}}
\newcommand{\bVm}{\bV^{\left(1\right)}}
\newcommand{\bVq}{\bV^{\left(2\right)}}
\newcommand{\sVn}{\sV^{\left(1\right)}}
\newcommand{\sVp}{\sV^{\left(2\right)}}
\newcommand{\tVm}{\tV^{\left(1\right)}}
\newcommand{\tVq}{\tV^{\left(2\right)}}
\newcommand{\braket}[2]{\left \langle #1 \middle| #2 \right \rangle}
\newcommand{\braketmatrix}[3]{\left \langle #1 \middle| #2 \middle| #3 \right \rangle}


\newcommand{\FoxT}[4]{\mathbbmss{H}_{#1:#2}\left\{#3;#4\right\}}
\newcommand{\oV}{\mathcal{O}}
\newcommand{\FHT}[2]{\xleftrightarrow[\left(#1;#2\right)]{\mathbbmss{H}}}
\newcommand{\rvec}[1]{\accentset{\leftarrow}{#1}}

\newcommand{\Lp}[2]{\mathfrak{L}_{#1}\left(#2\right)}
\newcommand{\DHT}[2]{\xleftrightarrow[\left(#1:#2\right)]{\mathbbmss{H}^\star}}
\newcommand{\DFoxT}[4]{\mathbbmss{H}^\star_{\left(#1:#2\right)}\left\{#3;#4\right\}}

\newcommand{\eOP}[3]{\left\langle #1,#2,#3\right|}
\newcommand{\bra}[1]{\left\langle #1\right|}
\newcommand{\ket}[1]{\left|#1\right\rangle}
\newcommand{\stdOP}[2]{#1 \boxdot #2}
\newcommand{\canOP}[2]{#1 \boxplus #2}

\newcommand{\nFoxV}[5]{\accentset{\circ}{\mathscr{H}}^{#1,#2}_{#3,#4}\left(#5\right)}
%\newcommand{\nFoxV}[5]{\mathscr{NH}^{#1,#2}_{#3,#4}\left(#5\right)}

\newcommand{\FoxRV}[2]{\mathscr{H}\left(#1:#2\right)}
%\newcommand{\nFoxRV}[2]{\accentset{\circ}{\mathscr{H}}\left(#1;#2\right)}
\newcommand{\nFoxRV}[3]{\grave{\mathscr{H}}_{#3}\left(#1:#2\right)}


\newcommand{\GFox}[6]{H^{#1}_{#2}
                        \left[
                            \begin{matrix}
                            {#3} \\  {#4}
                            \end{matrix}
                            \left|
                            \begin{array}{c}
                                {#5}
                                \\
                                {#6}
                            \end{array}
                            \right.
                        \right]}

\newcommand{\FoxTs}[5]{\mathbbmss{H}_{#1:#2}\left\{#3;#4\right\}_{\left\langle#5\right\rangle}}

\newcommand{\FoxHT}[5]{\mathbbmss{H}^{#1}_{#2}\left(#3\right)\left\{#4;#5\right\}}
\newcommand{\FoxHTs}[6]{\mathbbmss{H}^{#1}_{#2}\left(#3\right)\left\{#4;#5\right\}_{\left\langle#6\right\rangle}}


\newcommand{\pe}[1]{\pDefine{e}_{#1}}
\newcommand{\pf}[1]{\pDefine{f}_{#1}}
\newcommand{\pE}[1]{\pDefine{E}_{#1}}
\newcommand{\pF}[1]{\pDefine{F}_{#1}}
\newcommand{\eV}{\BB{\pDefine{e}}}
\newcommand{\fV}{\BB{\pDefine{f}}}
\newcommand{\EV}{\BB{\pDefine{E}}}
\newcommand{\FV}{\BB{\pDefine{F}}}

\newcommand{\pAlpha}[1]{\pDefine{\alpha}_{#1}}
\newcommand{\pBeta}[1]{\pDefine{\beta}_{#1}}
\newcommand{\alphaV}{\BB{\pDefine{\alpha}}}
\newcommand{\betaV}{\BB{\pDefine{\beta}}}
\newcommand{\alphaVn}{\alphaV^{\left(1\right)}}
\newcommand{\alphaVp}{\alphaV^{\left(2\right)}}
\newcommand{\betaVm}{\betaV^{\left(1\right)}}
\newcommand{\betaVq}{\betaV^{\left(2\right)}}

\newcommand{\TwoFoxH}[6]{H^{#1}_{#2}
                        \left[
                            \begin{matrix}
                            {#3} \\  {#4}
                            \end{matrix}
                            \left|
                            \begin{array}{c}
                                {#5}
                                \\
                                {#6}
                            \end{array}
                            \right.
                        \right]}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%------- enumitem: Customize space in itemize ----------
% \topsep = space between first item and preceding paragraph
% \partopsep = extra space added to \topsep when environment starts
%    a new paragraph.

\usepackage{enumitem}

\setenumerate{topsep=0.45em, partopsep=0em, parsep=0.3em,
itemsep=0em}

%\setitemize{topsep=0.45em, partopsep=0em, parsep=0.3em, itemsep=0em}


%\renewcommand{\rmdefault}{phv} % Arial
%\renewcommand{\sfdefault}{phv} % Arial
\usepackage{palatino} 


\setitemize{topsep=0.3em, partopsep=0em, parsep=0.1em,
itemsep=0.2em}

\usepackage{pifont} 

%\addtolength{\parskip}{0.4ex}

\newtheorem{keynote}{}
\newtheorem{postulate}{Postulate}

%\renewcommand{\theequation}{\thesection.\arabic{equation}}
\renewcommand{\thefigure}{\thesection.\arabic{figure}}
%\renewcommand{\thekeynote}{\thesection.\arabic{keynote}}


\newcommand{\mybox}[1]{
\begin{center}
   \framebox[10cm]{\raisebox{-0.45cm}{\bf \Large #1}}
\end{center}
\medskip }

\definecolor{MyBg}{RGB}{255,215,215}


\newcommand{\BoxNote}[3]{
	\begin{figure*}[!h]
	\begin{center} 
   		\colorbox{MyBg}{
         	\begin{minipage}[t]{0.975\textwidth}
			\vspace{0.2cm}
         		\begin{keynote} %\label{#1}
				\textbf{#2}
         		\end{keynote}
			{#3}
			\vspace{0.1cm} 
         	\end{minipage}
   		} 
	\end{center}
	\end{figure*}
}

\DeclareMathOperator{\AM}{\lvert}

 
\begin{document}

\begin{center}
Kyung Hee University\\
Communications and Quantum Information Laboratory\\[0.7cm]

{\LARGE \textbf{Notes : Introduction to Quantum Algorithms}}\\[0.7cm]
 Amirul Adlil Hakim\\ 
Director: Hyundong Shin\\[1cm]
\end{center}

(This is a note that I made by myself to study quantum algorithms from \cite{lin2022lecture}. All the contents was in the original source, I just paraphrased it here.)
\section{Preliminaries on quantum computation}
\subsection{Postulates on quantum mechanics}
\subsubsection{State space postulate}
A state space is a complex vector space with inner product structure, known as the Hilbert space $\mathcal{H}$, that is formed by a set of all quantum states of a quantum system.
The space $\mathcal{H}$ is isomorphic to some $\mathbb{C}^N$ if it is finite dimensional, and can be taken as $\mathcal{H} = \mathbb{C}^N$. We assume that $N = 2^n$ for some non-negative
integer $n$ which we will refer as qubits. A quantum state $\psi \in \mathbb{C}^N$ can be expressed in terms of its components as
\begin{equation}
    \psi = \begin{bmatrix}
        \psi_0 \\
        \psi_1 \\
        \cdot \\
        \cdot \\
        \psi_{N-1}
    \end{bmatrix},
\end{equation}
that has a Hermitian conjugate which is
\begin{equation}
    \psi^\dagger = \begin{bmatrix}
        \psi_0^* & \psi_1^* & \cdot & \cdot & \psi_{N-1}^*
    \end{bmatrix}.
\end{equation}
We use the Dirac notation, $\ket{\psi}$ for the quantum state and $\bra{\psi^\dagger}$ for its Hermitian conjugate. Using this notation, we can denote the inner product between two quantum states as below
\begin{equation}
    \braket{\psi}{\phi} = \psi^\dagger\phi = \sum_{i=0}^{N-1}\psi_i^*\phi_i.
\end{equation} 
We can denote the basis of $\mathbb{C}^N$ as $\{\ket{i}\}$, then to find the $i$-th component of $\ket{\phi}$, we can use the inner product $\ket{\phi_i} = \braket{i}{\phi}$. A projection operator can be defined as a matrix 
that is constructed by the outer product $\bra{\phi}\ket{\psi}$. To find the $(i,j)$-th component of the projection operator matrix, we can use 
\begin{equation}
    \bra{i}\ket{\phi}\bra{\psi}\ket{j} = \braket{i}{\phi}\braket{\psi}{j}.
\end{equation}
We assume that the state $\ket{\psi}$ is always normalized, $\braket{\psi}{\psi} = 1$, because the state vectors $\ket{\psi}$ and $c\ket{\psi}$ correspond to the same physical state. If $\ket{\phi}$ is normalized, then $c = e^{i\theta}$ for some $\theta \in [0,2\pi)$,
which we refer as the global phase.

For example, a single qubit can be expressed as a vector that lives in $\mathcal{H} = \mathbb{C}^2$. We can choose one basis for this Hilbert space, namely
\begin{equation}
    \ket{0} = \begin{bmatrix}
        1 \\
        0
    \end{bmatrix}, \quad \ket{1} = \begin{bmatrix}
        0 \\
        1
    \end{bmatrix}.
\end{equation}
In the context of spin-$\frac{1}{2}$ system which the space state is isomorphic to $\mathbb{C}^2$, the basis above can be seen as representing the spin-up ($\ket{0}$) and spin-down ($\ket{1}$). By using this basis, we can represent a general vector in this space state
\begin{equation}
    \ket{\psi} = \begin{bmatrix}
        \alpha \\
        \beta
    \end{bmatrix} = \alpha\ket{0} + \beta\ket{1},
\end{equation}
which implies $|\alpha|^2 + |\beta|^2 = 1$ because of normalization. More generally, we can write $\ket{\psi}$ as 
\begin{equation}
    \ket{\psi} = \alpha\ket{0} + \beta\ket{1} = \cos(\theta/2)\ket{0} + e^{i\phi}\sin(\theta/2)\ket{1},
\end{equation}
where $0\leq\theta<\pi$, $0\leq\psi<2\pi$. By using these angles, we can represent any single qubit state in a three-dimensional sphere known as the Bloch Sphere, where each state can be represented As
\begin{equation}
    a = (\sin\theta\cos\psi, \sin\theta\sin\psi, \cos\theta)^T.
\end{equation}

\subsubsection{Quantum operator postulate}
A quantum state can evolve from $\ket{\psi} \rightarrow \ket{\psi^{'}} \in \mathbb{C}^N$ if a unitary operator $U \in \mathbb{C}^{N\times N}$ acts on it, such that
\begin{equation}
    \ket{\psi^{'}} = U\ket{\psi}.   
\end{equation}
The gate in quantum computing typically use this unitary operator, one example is the Pauli matrices defined as follows
\begin{equation}
    \sigma_x = \begin{bmatrix}
        0 & 1 \\
        1 & 0
    \end{bmatrix}, \quad \sigma_y = \begin{bmatrix}
        0 & -i \\
        i & 0
    \end{bmatrix}, \quad \sigma_z = \begin{bmatrix}
        1 & 0 \\
        0 & -1
    \end{bmatrix}.
\end{equation}
Another examples are the Hadamard gate, the phase gate, and the T gate
\begin{equation}
    H = \frac{1}{\sqrt{2}}\begin{bmatrix}
        1 & 1 \\
        1 & -1
    \end{bmatrix}, \quad P = \begin{bmatrix}
        1 & 0 \\
        0 & i
    \end{bmatrix}, \quad T = \begin{bmatrix}
        1 & 0 \\
        0 & e^{i\pi/4}
    \end{bmatrix}.
\end{equation}

As mentioned before,the evolution of a quantum state at time $t_1$ into $t_2$ is caused by a unitary operator $U(t_2, t_1)$, in which the two quantum states has a linear relation
\begin{equation}
    \ket{\psi(t_2)} = U(t_2, t_1)\ket{\psi(t_1)}.
\end{equation}
If a time-independent Hamiltonian acts on a quantum state, then we have the following Schr\"{o}dinger equation,
\begin{equation}
    i\frac{d\ket{\psi(t)}}{dt} = H\ket{\psi(t)},
\end{equation}
where $H = H^\dagger$ is Hermitian. From the above equation, we can obtain the time evolution operator based on the Hamiltonian
\begin{equation}
    U(t_2, t_1) = e^{-iH(t_2 - t_1)}.
\end{equation}

\subsubsection{Quantum measurement postulate}
The type of quantum measurement that will be discussed here is the projective measurement. The projective measurement can be used to express all quantum measurements of the type positive operator-valued measure (POVM).

Any finite dimensional quantum observable can be represented by a Hermitian matrix that has spectral decomposition
\begin{equation}
    M = \sum_{m=0}^{M-1}\lambda_mP_m,
\end{equation}
where $\lambda_m \in \mathbb{R}$ are the eigenvalues of $M$ and $P_m$ are the projection operator onto the eigenspace of $\lambda_m$.  
The measurement of a quantum state by an observable $M$ will always result in one of its eigenvalues $\lambda_m$ with probability 
\begin{equation}
    p(m) = \bra{\psi}P_m\ket{\psi}.
\end{equation}
A measurement will change the quantum state in a non-unitary manner 
\begin{equation}
    \ket{\psi^{'}} = \frac{P_m\ket{\psi}}{\sqrt{p(m)}}.
\end{equation}

To calculate the expectation value of a quantum observable, we first notice that 
\begin{equation}
    \sum_mP_m = I \implies \sum_mp_m = \sum_m\bra{\psi}P_m\ket{\psi} = 1.
\end{equation}
This and the fact that $p_m \geq 0$ implies that $\{p_m\}$ is a probability distribution. 
Therefore, the expectation value of the measurement outcome can be calculated as 
\begin{equation}
    \mathbb{E}_\psi(M) = \sum_m\lambda_mp(m) = \sum_m\lambda_m\bra{\psi}P_m\ket{\psi} = \braketmatrix{\psi}{\sum_m\lambda_mP_m}{\psi}=\bra{\psi}M\ket{\psi}.
\end{equation}

As an example, suppose that $M = X$, then
\begin{equation}
    X\ket{\pm} = \lambda_{\pm}\ket{\pm},
\end{equation}
where $\ket{\pm} = \frac{1}{\sqrt{2}}(\ket{0} \pm \ket{1})$ and $\lambda_{\pm} = \pm 1$. From this, we can obtain the eigendecomposition of $M$,
\begin{equation}
    M = X = \ket{+}\bra{+} - \ket{-}\bra{-}.
\end{equation}
If we have a quantum state $\ket{0} = \frac{1}{\sqrt{2}}(\ket{+} + \ket{-})$, then the expectation value of $X$ is $\frac{1}{2}$.

\section{Grover's algorithm}
\subsection{Deutsch's algorithm}
The problem that this algorithm can solve can be analoized as this one: We have two boxes, each of them may contain either an apple or an orange. How do we know
if the two boxes contain the same fruit or not? We can open the two boxes to know the type of the fruit in each box, it is impossible to know whether the two boxes contain
the same fruits or not without knowing them. Deutsch's algorithm tries to solve this problem without knowing the fruit in each box. This kind of problem can be modelled mathematically as follows: Consider
a boolean function $f:\{0,1\} \rightarrow \{0,1\}$, the question is whethere $f(0) = f(1)$ or $f(0) \neq f(1)$. A quantum fruit-checker uses a quantum oracle to implement a function $f$ such as 
\begin{equation}
    U_f\ket{x,y} = \ket{x,y\oplus f(x)}, \quad x,y \in \{0,1\},
    \end{equation}
    while a classical fruit-checker can only query $U_f$ as 
    \begin{equation}
        U_f\ket{0,0} = \ket{0,f(0)}, \quad U_f\ket{0,1} = \ket{0,f(1)}, \quad U_f\ket{1,0} = \ket{1,f(0)}, \quad U_f\ket{1,1} = \ket{1,f(1)}.
    \end{equation}
The quantum fruit-checker can apply $U_f$ to a linear combination of states in the computational basis. We can show that $U_f$ is unitary.
\begin{equation} \label{eq1}
    \begin{split}
    \bra{x^{'},y^{'}}U^\dagger_f{U_f\ket{x,y}} & = \braket{x^{'},y^{'}\oplus f(x^{'})}{x,y\oplus f(x)} \\
     & = \braket{x^{'}}{x}\braket{y^{'}\oplus f(x^{'})}{y\oplus f(x)} \\
     & = \delta_{x,x^{'}}\delta_{y,y^{'}} \\
    \end{split}
    \end{equation}
which gives $U^\dagger_fU_f = I$.

The Deutsch's algorithm convert the oracle $U_f$ into a phase kickback. Let $\ket{y} = \ket{-} = \frac{1}{\sqrt{2}}(\ket{0} - \ket{1}),$ then
\begin{equation}
    U_f\ket{x,y} = \frac{1}{\sqrt{2}}(\ket{x,f(x)} - \ket{x,1\oplus f(x)}) = (-1)^{f(x)}\ket{x,y}.
\end{equation}
We know that $\ket{y} = HX\ket{0}$, then we can write 
\begin{equation}
    (I\oplus XH)U_f(I\oplus HX)\ket{x,0} = (-1)^{f(x)}\ket{x,0}.
\end{equation}
The $XH$ application can be viewed as the uncomputation step. Focusing on the first qubit only, we have 
\begin{equation}
    \tilde{U}_f\ket{x} = (-1)^{f(x)}\ket{x}.
\end{equation}
The information of $f(x)$ is stored as a phase factor of $\ket{x}$. The quantum operation for Deutsch's algorithm is as follows:
\begin{align}
        \ket{0,1} &\xrightarrow{H\otimes H}{\ket{+,-}} = \frac{1}{2}(\ket{0}+\ket{1})\otimes\ket{-}  \nonumber \\
        &\xrightarrow{U_f}{\frac{1}{2}(\ket{0}(-1)^{f(0)} + \ket{1}(-1)^{f(1)})\otimes\ket{-}} \nonumber\\
        &\xrightarrow{H\otimes I}\frac{1}{2}((-1)^{f(0)} + (-1)^{f(1)})\ket{0,-} + \frac{1}{2}((-1)^{f(0)} - (-1)^{f(1)})\ket{1,-}. \nonumber\\
\end{align}
We only need one query of $U_f$ to check if the boxes contain the same fruits or not. When we have $f(0) = f(1)$, measuring the first qubit will result in 0 deterministically, and if we have $f(0) \neq f(1)$, then measuring the first qubit
will result in 1 deterministically. 

\subsection{Unstructured search problem}
Now we want to find one box with an orange among $N = 2^n$ boxes, and each of other boxes contain an apple. Mathematically, we have a boolean function $f: \{0,1\}^n \rightarrow \{0,1\}$, and we want to find one marked $x_0$ such that $f(x_0) = 1$. In the worst scenario of the classical method, 
we need to open $N-1$ boxes to get $x_0$. Using a quantum algorithm known as the Grover's algorithm that relies to an oracle 
\begin{equation}
    U_f\ket{x,y} = \ket{x, y\oplus f(x)}, \quad x \in \{0,1\}^n, y \in \{0,1\},
\end{equation}
we can find $x_0$ with $\mathcal{O}(\sqrt{N})$ queries. The classical probabilistic algorithm can only work on the probability density while the quantum algorithms can work with 
wavefunction amplitudes, of wich the square results in the probability densities. This is the source of  the quadratic speedup of the Grover's algorithm. 

The scenario of Grover's algorithm is as follows: we have an initial state which is the uniform superposition of all possible states; 
\begin{equation}
    \ket{\psi_0} = \frac{1}{\sqrt{N}}\sum_{x=0}^{N-1}\ket{x}.
\end{equation}
This superposition can be prepared by using the Hadamard gates on $n$ qubits, as follows: 
\begin{equation}
    \ket{\psi_0} = H^{\otimes n}\ket{0^n}.
\end{equation}
To find the state $\ket{x_0}$, we would like to amplifiy its wavefunction amplitude from $1/\ket{N}$ to $\sqrt{p} = \Omega(1)$ by using only $\mathcal{O}(\sqrt{N})$ queries to the oracle $U_f$. By measuring 
the amplitude-amplified state, we can get an output state $\ket{x}$. To check if $x = x_0$, we apply another query of $U_f$ such that $U_f\ket{x,0} = \ket{x, f(x)}$. We will get $f(x) = 1$ with probability $p$. It's still probabilistic, so if we don't get the right $x_0$ for the first time, 
we repeat the process. We will obtain $x_0$ with high probability after $\mathcal{O}(1/p)$ times of repetition.

The first step of the Grover's algorithm is we take $\ket{y} = \ket{-}$ and then we turn the oracle into a phase kickback
\begin{equation}
    U_f\ket{x,-} = \frac{1}{\sqrt{2}}(\ket{x, f(x)} - \ket{x, 1\oplus f(x)}) = (-1)^{f(x)}\ket{x,-}.
\end{equation}
We can decompose any quantum state $\ket{\psi}$ as 
\begin{equation}
    \ket{\psi} = \alpha\ket{x_0} + \beta\ket{\psi_{\perp}},
\end{equation}
where $\braket{\psi_{\perp}}{\psi_0} = 0$. Therefore, we have 
\begin{equation}
    U_f\ket{\psi}\otimes\ket{-} = -\alpha\ket{x_0}\otimes\ket{-} + \beta\ket{\psi_{\perp}}\otimes\ket{-}.
\end{equation}
This is because $f(x) = 0$ for $x$ other than $x_0$. We can discard $\ket{-}$ to obtain an $n$-qubit unitary 
\begin{equation}
    R_{x_0}(\alpha\ket{\psi_0} + \beta\ket{\psi_{\perp}}) = -\alpha\ket{x_0} + \beta\ket{\psi_{\perp}}.
\end{equation}
Therefore, $R_{x_0}$ is a reflection operator across the hyperplane orthogonal to $\ket{x_0}$ which is known as the Householder reflector 
\begin{equation}
    R_{x_0} = I - 2\ket{x_0}\bra{x_0}.
\end{equation}

We can write 
\begin{equation}
    \ket{\psi_0} = \sin(\theta/2)\ket{x_0} + \cos(\theta/2)\ket{\psi_{0\perp}},
\end{equation}
where $\theta = 2\sin^{-1}\frac{1}{\sqrt{N}} \approx \frac{2}{\sqrt{N}}$ and $\ket{\psi_{0\perp}} = \frac{1}{\sqrt{N-1}}\sum_{x\neq x_0}\ket{x}$. Then 
\begin{equation}
    R_{x_0}\ket{\psi_0} = -\sin(\theta/2)\ket{x_0} + \cos(\theta/2)\ket{\psi_{0\perp}}.
\end{equation}
Thus span$\{\ket{x_0},\ket{\psi_{0\perp}}\}$ is an invariant subspace of $R_{x_0}$. 

We can consider another Householder reflector, 
\begin{equation}
    R_{\psi_{0}} = -(I - 2\ket{\psi_{0\perp}}\bra{\psi_{0\perp}}).
\end{equation}
By using both of the Householder reflectors, we can obtain 
\begin{align}
    R_{\psi_{0}}R_{x_0}\ket{\psi_0} &= R_{\psi_0}(\ket{\psi_0} - 2\sin(\theta/2)\ket{x_0}) \nonumber \\
    &= (\ket{\psi_0} - 4\sin^2(\theta/2)\ket{\psi_0}) + 2\sin(\theta/2)\ket{x_0} \nonumber \\ 
    &= \sin(\theta/2)(3 - 4\sin^2(\theta/2))\ket{\psi_0} + \cos(\theta/2)(1 - 4\sin^2(\theta/2))\ket{\psi_{0\perp}}\nonumber \\ 
    &= \sin(3\theta/2)\ket{x_0} + \cos(3\theta/2)\ket{\psi_{0\perp}}.\nonumber \\ 
\end{align}
We dub the operator above as the Grover operator $G$. We can see that it amplifies the amplitude of $x_0$ from $\sin(\theta/2)$ into $\sin(3\theta/2)$ while decreasing the amplitude of the states orthogonal to $\ket{x_0}$. We can apply $G$ for $k$ times to obtain 
\begin{equation}
    G^k\ket{\psi_0} = \sin((2k+1)\theta/2)\ket{x_0} + \cos((2k+1)\theta/2)\ket{\psi_{0\perp}}.
\end{equation}
We want the amplitude of $\ket{x_0}$ as close as 1 as possible. Thus for $\sin(2k+1)\theta/2 \approx 1$, we need $k \approx \frac{\pi}{2\theta} - \frac{1}{2}\approx \frac{\pi}{4}\sqrt{N}$ (because $\theta \approx 2/\sqrt{N}$). This proves that it takes $\mathcal{O}(\sqrt{N})$ queries to find the marked state $x_0$ by using the Grover's algorithm.

\subsection{Amplitude amplification}
Another use case of the Grover's algorithm other than the unstructured search is amplitude amplification. Suppose we want to prepare $\ket{\psi_0}$ by using an oracle $U\ket{0^n} = \ket{\psi_0}$ and the $\ket{\psi_0}$ itself is a superposition state as follows:
\begin{equation}
    \ket{\psi_0} = \sqrt{p_0}\ket{\psi_{\text{good}}} + \sqrt{1-p_0}\ket{\psi_{\text{bad}}}.
\end{equation}
We want the state $\ket{\psi_{\text{good}}}$ but cannot obtain it directly, but we have hope to obtain a state that is largely overlap with $\ket{\psi_{\text{good}}}$. In other words, we want to amplify its amplitude. 

If we bring this problem into the unstructured search problem, we have $\ket{\psi_{\text{good}}} = \ket{x_0}$ and $p_0 = 1/N$. We don't have access to the answer $\ket{x_0}$ but we assume that we have access to its reflection operator. In this problem, we also assume that we have access to the reflection operator 
\begin{equation}
    R_{\text{good}} = I - 2\ket{\psi_{\text{good}}}\bra{\psi_{\text{good}}}.
\end{equation}
By using the oracle $U_{\psi_0}$, we can construct the reflection with respect to the initial state 
\begin{equation}
    R_{\psi_0} = 2\ket{\psi_0}\bra{\psi_0} - I = U_{\psi_0}(2\ket{0^n}\bra{0^n} - I)U_{\psi_0}^\dagger.
\end{equation}
Therefore, we obtain two reflection operators that can be used to construct the Grover operator, 
\begin{equation}
    G = R_{\psi_0}R_{\text{good}}.
\end{equation}
We can obtain a state that has $\omega(1)$ overlap with $\ket{\psi_{\text{good}}}$ by applying $G^k$ to $\ket{\psi_0}$ for some $k = \mathcal{O}(1/\sqrt{p_0})$.

\subsection{Lower bound of query complexity}
The Grover's algorithm can find $x_0$ with constant probability by making $\mathcal{O}(\sqrt{N})$ times querying $R_{x_0}$. There has not been any quantum algorithm that can do it fewer than $\Omega(\sqrt{N})$ access to $R_{x_0}$.

Generally, we can express any quantum search algorithm that starts from an initial state $\ket{\psi_0}$ and queries $R_{x_0}$ for $k$ steps as the following 
\begin{equation}
    \ket{\psi_k^{x_0}} = U_k^{x_0}\ket{\psi_0} = U_kR_{x_0}U_{k-1}R_{x_0}\cdots U_1R_{x_0}\ket{\psi_0},
\end{equation}
for some unitaries $\{U_i\}$. For simplicity, we can assume that the algorithm does not use any ancilla qubit, as the result can be generalized to the case in the presence of ancilla qubits. The superscipt $x_0$ indicates that the state depends on the marked state $x_0$, and solving the search problem means we obtain $\ket{\psi_k^{x_0}}$ such that 
\begin{equation}
    |\braket{\psi_k^{x_0}}{x_0}|^2 \geq \frac{1}{2}.
\end{equation}
In other words, we can obtain $\ket{x_0}$ with probability at least $1/2$ by measuring $\ket{\psi_k^{x_0}}$ in the computational basis. We can prove the queries lower bound of the quantum search algorithm by comparing the action of $U_k^{x_0}$ with a "fake algorithm" with the unitary $U_k$ that can be defined as follows 
\begin{equation}
    \ket{\psi_k} = U_k\ket{\psi_0} = U_kU_{k-1}\cdots U_1\ket{\psi_0}.
\end{equation}
We can not obtain the marked state $x_0$ from this algorithm because its final state $\ket{\psi_k}$ does not contain any information of $x_0$.

We will use the following discrete $l_2$-norm
\begin{equation}
    ||f||_{l_2} = \sqrt{\sum_{x_0\in[N]}||f^{x_0}||},
\end{equation}
for a set of vectors $\{f^{x_0}\}_{x_0\in[N]}$ and each $f^{x_0} \in \mathbb{C}^N$. We also have the following inequality 
\begin{equation}
    ||f||_{l_2} - ||g||_{l_2} \leq ||f + g||_{l_2} \leq ||f||_{l_2} + ||g||_{l_2}.
\end{equation}

We will prove the lower bound with two steps. The first step is we will show the difference between the true and the fake solution as follows 
\begin{equation}
    D_k = \sum_{x_0\in[N]}||\ket{\psi_k^{x_0}} - \ket{\psi_k}||^2 = \Omega(N).
\end{equation}
In the second step, we will prove that 
\begin{equation}
    D_k \leq 4k^2, \quad k \geq 0,
\end{equation}
and $D_0 = 0$. Therefore, we must have $k = \Omega(\sqrt{N})$. 

In the first step, we can choose a phase factor $e^{i\theta}$ such that 
\begin{equation}
    \braket{\psi_k^{x_0}}{x_0} \geq \frac{1}{\sqrt{2}}.
\end{equation}
Therefore, using Cauchy-Schwarz inequality, we have
\begin{equation}
    ||\ket{\psi_k^{x_0}} - \ket{x_0}||^2 = 2 - 2\braket{\psi_k^{x_0}}{x_0} \leq 2 - \sqrt{2}.
\end{equation}
Therefore, we have 
\begin{equation}\label{distance_bound}
    \sum_{x_0\in[N]}||\ket{\psi_k^{x_0}} - \ket{x_0}||^2  \leq 2N - \sqrt{2}N.
\end{equation}
Meanwhile, from the fake algorithm, we  will have 
\begin{equation}
    \sum_{x_0\in[N]}||\ket{\psi_k} - \ket{x_0}||^2 \geq 2N - 2\sum_{x_0\in[N]}|\braket{x_0}{\psi}|  = 2N - 2\sqrt{N},
\end{equation}
which violates the bound in (\ref*{distance_bound}). 
From the two equations above, by using the triangle inequality, we have 
\begin{align}
    D_k = \sum_{x_0\in[N]}||\ket{\psi_k^{x_0}} - \ket{\psi_k}||^2 &= \sum_{x_0\in[N]}||(\ket{\psi_k^{x_0}} - \ket{x_0}) - (\ket{\psi_x} - \ket{x_0})||^2 \\
    &\geq \left(\sqrt{\sum_{x_0\in[N]}||\ket{\psi_k} - \ket{x_0}||^2} - \sqrt{\sum_{x_0\in[N]}||\ket{\psi_k^{x_0}} - \ket{x_0}||^2}\right)^2 \\
    &\geq (\sqrt{2N - 2\sqrt{N}} - \sqrt{2N - \sqrt{2}N})^2 = \Omega(N).
\end{align}
In other words, we found that the true solution and the fake solution must be well seperated in $l_2$-norm.

\section{Quantum Phase Estimation}
Let's say we have a unitary $U$ and its eigenvector $\ket{\psi}$ such that 
\begin{equation}
    U\ket{\psi} = e^{2\pi i\theta}\ket{\psi},\quad \theta \in [0,1),
\end{equation}
and we want to find $\theta$ to a certain precision. This is a task for quantum phase estimation. Using classical computer, we can estimate $\theta$ by using the element-wise division like the following 
\begin{equation}
    \bra{j}U\ket{\psi}/\braket{j}{\psi} = e^{2\pi i\theta },
\end{equation}
for any $j$ in the computational basis. Unfortunately, we cannot implement the element-wise division efficiently on a quantum computer, therefore, we need another algorithm that can work on a quantum computer. 

\subsection{Hadamard test}
Hadamard test is a useful tool for computing the expectation value of a unitary operator with respoect to a state, $\bra{\psi}U\ket{\psi}$. The unitary $U$ is generally not Hermitian, therefore $\bra{\psi}U\ket{\psi}$ does not correspond to the measurement of a physical observable and we have to measure the real and imaginary part of the expectation value seperately. 

For the real Hadamard test, we have a circuit that does the following operation 
\begin{align}
    \ket{0}\ket{\psi} &\xrightarrow{H\otimes I}\frac{1}{\sqrt{2}}(\ket{0} + \ket{1})\ket{\psi} \nonumber \\
    &\xrightarrow{c-U}\frac{1}{\sqrt{2}}(\ket{0}\ket{\psi} + \ket{1}U\ket{\psi}) \nonumber \\
    &\xrightarrow{H\otimes I}\frac{1}{2}\ket{0}(\ket{\psi} + U\ket{\psi}) + \frac{1}{2}\ket{1}(\ket{\psi} - U\ket{\psi}).\nonumber \\
\end{align}
Therefore, the probability of measuring the qubit 0 to be in the state $\ket{0}$ is 
\begin{equation}
    p(0) = \frac{1}{2}(1 + \text{Re}(\bra{\psi}U\ket{\psi})).
\end{equation}
The imaginary part of the Hadamard test performs the following operation to $\ket{0}\ket{\psi}$ 
\begin{equation}
    \frac{1}{2}\ket{0}(\ket{\psi} - iU\ket{\psi}) + \frac{1}{2}\ket{1}(\ket{\psi} + iU\ket{\psi}).
\end{equation}
Therefore, the probability of mesuring the  qubit 0 to be in state $\ket{0}$ is 
\begin{equation}
    p(0) = \frac{1}{2}(1 + \text{Im}(\bra{\psi}U\ket{\psi})).
\end{equation}
The Hadamard test can be used to estimate $\theta$. For example in the case of real Hadamard test, the probability of measuring the qubit 0 to be in state $\ket{1}$ is 
\begin{equation}
    p(1) = \frac{1}{2}(1 - \text{Re}(\bra{\psi}U\ket{\psi})) = \frac{1}{2}(1 - \cos(2\pi\theta)),
\end{equation}
thus 
\begin{equation}
    \theta = \pm\frac{1}{2\pi}\cos^{-1}(1 - 2p(1)).
\end{equation}
If we assume that $\theta\approx 0$ and we would like to estimate it to additive precision $\epsilon$, we have 
\begin{equation}
    p(1)\approx(2\pi\theta)^2=\mathcal{O}(\epsilon^2).
\end{equation}
That means, $p(1)$ needs to be estimated to precision $\mathcal{O}(\epsilon^2)$ and the number of samples needed is $\mathcal{O}(1/\epsilon^2)$.

\subsection{Kitaev's method for quantum phase estimation}
From the previous subsection. we obtain that the number of measurement needed to estimate $\theta$ to precision $\epsilon$ is $\mathcal{O}(1/\epsilon^2)$. A procedure known as the Kitaev's method can improve the number of measurement quadratically $(\mathcal{O}(1/\epsilon))$. 

We assume that the eigenvalue can be exactly represented by using $d$ bits in the fixed point representation 
\begin{equation}
    \theta = 0.\theta_{d-1}\theta_{d-2}\cdots\theta_0.
\end{equation}
If $d = 1$, we have $\theta = 0.\theta_0$, where $\theta\in\{0,1\}$. Then we have $e^{i2\pi\theta} = e^{i\pi\theta_0}$. By using the real Hadamard test, we can obtain that $p(1) = 0$ if $\theta_0 = 0$ and $p(1) = 1$ if $\theta_0 = 1$, whcih is a deterministic result. We only need one measurement of qubit 1 to determine $\theta_0$.

If we consider $\theta = .0\cdot0\theta_0$, we need to reach precision $\epsilon < 2^{-d}$ to determine the value of $\theta_0$. This means we need $\mathcal{O}(1/\epsilon^2) = \mathcal{O}(2^{2d})$ repeated measurements or number of queries to $U$. In the Kitaev's method, we have access to $U^j$ for a suitable power $j$ to reduce the number of queries to $U$. Specifically, if we can query $U^{2^{d-1}}$, then we have 
\begin{equation}
    p(1) = \frac{1}{2}(1 - \cos(2\pi.\theta_0)) = \begin{cases}
        0, & \text{if } \theta_0 = 0, \\
        1, & \text{if } \theta_0 = 1.
    \end{cases}
\end{equation}
The total number of queries of $U$ becomes $\mathcal{O}(2^d)$ and the result is again deterministic.

As we explained above, the Kitaev's method use a more complex quantum circuit with a larger circuit depth to reduce the total number of queries. Instead of estimating $\theta$ from a single number, we estimate $\theta$ bit-by-bit by assuming access to $U^{2j}$. This allows us to estimate 
\begin{equation}
    2^j\theta = \theta_{d-1}\cdots\theta_{d-j}.\theta_{d-j-1}\cdots\theta_0 = .\theta_{d-j-1}\cdots\theta_0 \quad \text{mod } 1.
\end{equation}
The goal of the algorithm is to estimate the $d$ digits for any $\theta$, and we want to describe and analyze the performance. 

First, we can apply the circuit of the real hadamard test with $U^{2^j}$ with $j = 0,1,\cdots,d-3$ to estimate $p(0)$ fro each $j$ so the error in $2^j\theta$ is less than $1/16$, which means that any perturbation must be due to the 5th digit in the binary representation. We denote the closest 3-bit estimate of $\alpha_j$ mod 1 by $\beta_j$. For example, for $2^j\theta = 0.11110$, if $\alpha_j = 0.11101$, then $\beta_j = 0.1111$. But if $\alpha_j = 0.11111$, then $\beta_j = 0.0000$. Another example is if we have $2^j\theta = 0.11101$, if $\alpha_j = 0.11110$, then we have $\beta_j = 0.111$ for rounded down estimation and $\beta_j = 0.000$ for rounded up estimation. We can show that the uncertainty in $\alpha_j$ and $\beta_j$ is not detrimental to the algorithm.

Then, we can perform some post-processing. Start from $j = d-3$, we can estimate $.\theta_2\theta_1\theta_0$ to accuracy $1/16$. We will proceed with the iteration: for $j = d-4,\cdots,0$, we assign 
\begin{equation}
    \theta_{d-j-1} = \begin{cases}
        0, & |.0\theta_{d-j-2}\theta_{d-j-3} - \beta_j|_{\text{mod }1} < 1/4, \\
        1, & |.1\theta_{d-j-2}\theta_{d-j-3} - \beta_j|_{\text{mod }1} < 1/4.
    \end{cases}
\end{equation}
After running the algorithm above, we can recover $\theta = .\theta_{d-1}\cdots\theta_0$ exactly. The number of queries to $U$ is the total cost of Kitaev's method, which is $\mathcal{O}(\sum_{j=0}^{d-3}2^j) = \mathcal{O}(\epsilon^{-1})$.

For example, we consider $\theta = 0.\theta_4\theta_3\theta_2\theta_1\theta_0 = 0.11111$ with $d=5$. If we run the Kitaev's algorithm for $j = 0,1,2$, we will obtain 
\begin{equation*}
    \begin{tabular}{||c c c||} 
        \hline
        $j$ & $2^j\theta$ & $\text{possible }\beta_j$ \\ [0.5ex] 
        \hline\hline
        0 & 0.11111 & $\{0.111,0.000\}$  \\ 
        \hline
        1 & 0.1111 & $\{0.111,0.000\}$   \\
        \hline
        2 & 0.111 & $\{0.111\}$   \\
        \hline
        
       \end{tabular}
\end{equation*}
Start with $j = 2$, we only have one $\beta_j$, therefore we can recover $0.\theta_2\theta_1\theta_0 = 0.111$. For $j = 1$, we need to decide $\theta_3$ by using the above equation. If $\beta_j = 0.111$, we have $\theta_3 = 1$, and if $\beta_j = 0.000$, our choice is still $\theta_3 = 1$, since $|.011-.000|_{\text{mod }1} = 0.101 = 3/8 > 1/4$ and $|.111-.000|_{\text{mod }1} = 0.001 = 1/8 < 1/4$. We can also do the same for $j=0$, and we can obtain $\theta_4 = 1$, which recovers $\theta$ exactly.

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,QEM}


\end{document}